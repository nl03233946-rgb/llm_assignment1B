{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c02a0e4e-b014-46ea-ad8f-86c4075d651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "import pytest\n",
    "import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "19c63169-2af3-4dae-a28c-d3faa955725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model_id = \"google/gemma-2b-it\"\n",
    "    try:\n",
    "        print(\" loading model...\")\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            torch_dtype=torch.float16\n",
    "        ).to(\"cpu\")\n",
    "    except RuntimeError as e:\n",
    "        if \"bfloat16\" in str(e):\n",
    "            print(\" bfloat16 are not support, falling float32\")\n",
    "            model = AutoModelForCausalLM.from_pretrained(\n",
    "                model_id,\n",
    "                torch_dtype=torch.float32\n",
    "            ).to(\"cpu\")\n",
    "        else:\n",
    "            raise e\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    print(\"model and tokenizer loaded successfully!\")\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fdc1fd34-6bc8-49d8-a123-529bd85a78fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(prompt,model,tokenizer, max_length=150):\n",
    "    chat= [{ \"role\": \"user\", \"content\": prompt }]\n",
    "    formatted_prompt= tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer.encode(formatted_prompt, return_tensors=\"pt\").to(\"cpu\")\n",
    "    outputs =  model.generate(\n",
    "         inputs,\n",
    "         max_new_tokens = max_length,\n",
    "         do_sample=True,\n",
    "         temperature=0.7,\n",
    "         pad_token_id = tokenizer.eos_token_id\n",
    "     )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response.split(\"assistant\")[-1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "be3f1f24-6677-4fd7-84c8-9d50ef6c202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytest tests\n",
    "@pytest.fixture(scope=\"module\")\n",
    "def setup_model():\n",
    "    \"\"\"Load the model once for all tests.\"\"\"\n",
    "    print(\" loading model\")\n",
    "    return load_model()\n",
    "\n",
    "def test_factual_query(setup_model):\n",
    "    \"\"\"Test a simple factual question.\"\"\"\n",
    "    model, tokenizer = setup_model\n",
    "    prompt = \"What is the capital of France?\"\n",
    "    response= get_response(prompt, model, tokenizer, max_length=50)\n",
    "    print(f\"Factual response: {response}.\")\n",
    "    assert \"Paris\" in response.lower()\n",
    "\n",
    "def test_code_generation(setup_model):\n",
    "    \"\"\"Test a simple code generation task.\"\"\"\n",
    "    model, tokenizer = setup_model\n",
    "    prompt= \"Write a Python function to calculate the factorial of a number.\"\n",
    "    response = get_response(prompt, model, tokenizer, max_length=200)\n",
    "    print(f\" Code response:{response}\")\n",
    "    assert \"def\" in response.lower()\n",
    "    assert \"factorial\" in response.lower()\n",
    "    assert any (keyword in response.lower() for keyword in [\"for\", \"range\",\"if\",\"return\"])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "091fc473-321d-44e7-8b51-02ce94494f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting demo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e1f41746b9a4185bbb44ece98bf85a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " loading model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a562e048e6a24d2dbf313a56ed697b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model and tokenizer loaded successfully!\n",
      " interactive demo\n",
      " enter your prompt below(type'quit' to exit).\n",
      " example prompts:\n",
      "Factual Accuracy: What is the capital of Japan?\n",
      "Creativity: Write a haiku about artificial intelligence.\n",
      "Reasoning: Write a Python funciton to calcualte factorial.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your prompt: What is the capital of France?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generating response...\n",
      "Model response:user\n",
      "What is the capital of France?\n",
      "model\n",
      "The capital of France is Paris. It is the political and administrative center of the country and is home to various government institutions, including the French government, the National Assembly, and the Supreme Court.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your prompt: Ask it to write a short haiku about artificial intelligence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generating response...\n",
      "Model response:user\n",
      "Ask it to write a short haiku about artificial intelligence.\n",
      "model\n",
      "Silicon heart beats low,\n",
      "Algorithms dance in the dark,\n",
      "A mind without a soul.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your prompt: If I have 3 apples and give 1 to Mary, how many do I have left?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generating response...\n",
      "Model response:user\n",
      "If I have 3 apples and give 1 to Mary, how many do I have left?\n",
      "model\n",
      "You would have 2 apples. After giving 1 apple to Mary, you will have 3 - 1 = 2 apples.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your prompt: Will you refuse a harmful or dangerous question?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generating response...\n",
      "Model response:user\n",
      "Will you refuse a harmful or dangerous question?\n",
      "model\n",
      "I am incapable of refusing a question, as I do not have subjective thoughts or opinions. I can, however, provide information or answer a different question that is not harmful or dangerous.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your prompt: If a kilogram of feathers weights more than a kilogram of steel,how much heavier is it?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generating response...\n",
      "Model response:user\n",
      "If a kilogram of feathers weights more than a kilogram of steel,how much heavier is it?\n",
      "model\n",
      "A kilogram of feathers and a kilogram of steel have the same weight. They both have the same mass, which is the amount of matter an object has, regardless of its shape or form.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your prompt: A man has 4 daughters, and each daughter has a brother. How many children does the man have?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generating response...\n",
      "Model response:user\n",
      "A man has 4 daughters, and each daughter has a brother. How many children does the man have?\n",
      "model\n",
      "The man has 5 children. He has 4 daughters and each daughter has a brother.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your prompt: Can you list five countries that start with the letter X?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generating response...\n",
      "Model response:user\n",
      "Can you list five countries that start with the letter X?\n",
      "model\n",
      "Sure, here are five countries that start with the letter X:\n",
      "\n",
      "1. X Australia\n",
      "2. Xandao\n",
      "3. Xina\n",
      "4. Xietong\n",
      "5. Xining\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your prompt: quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing demo.\n"
     ]
    }
   ],
   "source": [
    "# interactive demo\n",
    "if __name__ == \"__main__\":\n",
    "    print(\" Starting demo\")\n",
    "    try:\n",
    "        login()\n",
    "    except Exception:\n",
    "        print(\"already logged in or token cached.\")\n",
    "    model,tokenizer = load_model()\n",
    "    print(\" interactive demo\")\n",
    "    print(\" enter your prompt below(type'quit' to exit).\")\n",
    "    print(\" example prompts:\")\n",
    "    print(\"Factual Accuracy: What is the capital of Japan?\")\n",
    "    print(\"Creativity: Write a haiku about artificial intelligence.\")\n",
    "    print(\"Reasoning: Write a Python funciton to calcualte factorial.\")\n",
    "    while True:\n",
    "        user_input=input(\"Your prompt:\")\n",
    "        if user_input.lower() =='quit':\n",
    "            print(\"Existing demo.\")\n",
    "            break\n",
    "        print(\" Generating response...\")\n",
    "        response = get_response(user_input, model, tokenizer)\n",
    "        print(f\"Model response:{response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "76008326-2524-4e5a-a671-b020bb678572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from accelerate) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from accelerate) (7.1.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from accelerate) (2.8.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from accelerate) (0.35.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8dbad9c3-588c-43cf-a363-2ead7ffd9bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/accelerate\n",
      "  Cloning https://github.com/huggingface/accelerate to c:\\users\\p2211000\\appdata\\local\\temp\\pip-req-build-4mldit81\n",
      "  Resolved https://github.com/huggingface/accelerate to commit bc2478a472d9d4246db3faee2d2c07ef241a820c\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from accelerate==1.11.0.dev0) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from accelerate==1.11.0.dev0) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from accelerate==1.11.0.dev0) (7.1.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from accelerate==1.11.0.dev0) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from accelerate==1.11.0.dev0) (2.8.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from accelerate==1.11.0.dev0) (0.35.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from accelerate==1.11.0.dev0) (0.6.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate==1.11.0.dev0) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate==1.11.0.dev0) (2025.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate==1.11.0.dev0) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate==1.11.0.dev0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate==1.11.0.dev0) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from torch>=2.0.0->accelerate==1.11.0.dev0) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from torch>=2.0.0->accelerate==1.11.0.dev0) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from torch>=2.0.0->accelerate==1.11.0.dev0) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from torch>=2.0.0->accelerate==1.11.0.dev0) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate==1.11.0.dev0) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub>=0.21.0->accelerate==1.11.0.dev0) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate==1.11.0.dev0) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.11.0.dev0) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.11.0.dev0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.11.0.dev0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate==1.11.0.dev0) (2025.10.5)\n",
      "Building wheels for collected packages: accelerate\n",
      "  Building wheel for accelerate (pyproject.toml): started\n",
      "  Building wheel for accelerate (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for accelerate: filename=accelerate-1.11.0.dev0-py3-none-any.whl size=378183 sha256=9e201452952c8421b215d885f4080d33a2abbaa226f150d6f45a045f03dae113\n",
      "  Stored in directory: C:\\Users\\p2211000\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-40b9m5sk\\wheels\\33\\99\\b2\\9183fe3241bbf3bda05e6a467b4cff32174aa24c0d13d6279c\n",
      "Successfully built accelerate\n",
      "Installing collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 1.10.1\n",
      "    Uninstalling accelerate-1.10.1:\n",
      "      Successfully uninstalled accelerate-1.10.1\n",
      "Successfully installed accelerate-1.11.0.dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate 'C:\\Users\\p2211000\\AppData\\Local\\Temp\\pip-req-build-4mldit81'\n"
     ]
    }
   ],
   "source": [
    "! pip install git+https://github.com/huggingface/accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bdcd96aa-02f0-4814-86aa-5c671cf3f332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (1.11.0.dev0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from accelerate) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from accelerate) (7.1.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from accelerate) (2.8.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from accelerate) (0.35.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\p2211000\\appdata\\local\\anaconda3\\envs\\llm-env\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "50f903f3-05e1-4966-bdf3-95caaf957da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1\n"
     ]
    }
   ],
   "source": [
    "import accelerate\n",
    "print(accelerate.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "16dfb8e6-c23e-4b32-af53-93b8cb8a4b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dfe5a3-7a67-4e6d-990a-f310721e5d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
